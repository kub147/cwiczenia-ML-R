---
title: "Zadanie 4" 
author: Jakub Wilk
date: 2024-10-23
format:   
  html:    
    toc: true    
    toc-depth: 3    
    toc-location: right    
    toc-title: Spis Treści    
    number-sections: true    
    number-depth: 3    
    html-math-method: katex    
    code-tools: true    
    code-block-bg: true    
    code-fold: show    
    code-summary: "Show and hide code"    
    link-external-icon: true    
    link-external-newwindow: true    
    smooth-scroll: true    
    self-contained: true 
    theme:         
      dark: solar 
      light: flatly    
    fontsize: 1.0em    
    linestretch: 1.3    
    fig-align: center
execute:   
  echo: true  
  error: false  
  warning: false  
  output: true
---

# Przygotowanie środowiska
```{r}
library(tidymodels)
library(openair)
library(rpart.plot)
library(vip)
library(ranger)
library(recipes)
tidymodels_prefer()

# Ustawienie ziarna losowości
set.seed(123)
```

# Wczytanie i przygotowanie danych
```{r}
# Wczytanie danych z openair
air <- mydata |> 
  selectByDate(year = 2001) |>
  na.omit()

# Klasyfikacja wartości O3 na dwie kategorie
air <- air |> 
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 58),
    labels = c("Niskie", "Wysokie")
  )) |>
  select(-o3)

# Podział danych
split <- initial_split(air, prop = 0.75, strata = ozone)
train_data <- training(split)
test_data <- testing(split)
```

# Ćwiczenie 4.6 - Optymalizacja drzewa decyzyjnego

## Przygotowanie modelu i przepisu (recipe)
```{r}
# Tworzenie przepisu
air_recipe <- recipe(ozone ~ ., data = train_data) |>
  update_role(date, new_role = "predictor") |>
  step_date(date, features = c("dow", "month")) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

# Specyfikacja modelu z parametrami do dostrojenia
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune()
) |>
  set_engine("rpart") |>
  set_mode("classification")

# Utworzenie workflow
tree_workflow <- workflow() |>
  add_model(tree_spec) |>
  add_recipe(air_recipe)
```

## Przygotowanie siatki parametrów
```{r}
# Stworzenie siatki parametrów
tree_grid <- grid_regular(
  cost_complexity(),
  tree_depth(),
  levels = 5
)

# Przegląd siatki
print("Siatka parametrów:")
tree_grid
```

## Walidacja krzyżowa i dostrajanie
```{r}
# Przygotowanie foldów CV
set.seed(234)
folds <- vfold_cv(train_data, v = 5)

# Zdefiniowanie metryk oceny
metrics <- metric_set(
  accuracy,
  roc_auc,
  precision,
  recall
)

# Dostrajanie modelu
tree_tuning <- tune_grid(
  tree_workflow,
  resamples = folds,
  grid = tree_grid,
  metrics = metrics
)

# Wyświetlenie najlepszych wyników
print("Najlepsze wyniki dla drzewa decyzyjnego:")
show_best(tree_tuning, "accuracy")
```

## Finalizacja modelu drzewa
```{r}
# Wybór najlepszych parametrów
best_tree <- select_best(tree_tuning, "accuracy")

# Finalizacja workflow
final_tree_workflow <- finalize_workflow(
  tree_workflow,
  best_tree
)

# Dopasowanie finalnego modelu
final_tree_fit <- last_fit(
  final_tree_workflow,
  split
)

# Wyniki końcowe
print("Wyniki końcowe drzewa decyzyjnego:")
collect_metrics(final_tree_fit)

# Wizualizacja drzewa
final_tree_fit |>
  extract_workflow() |>
  extract_fit_engine() |>
  rpart.plot(roundint = FALSE)

# Ważność zmiennych
final_tree_fit |>
  extract_workflow() |>
  extract_fit_parsnip() |>
  vip()
```

# Ćwiczenie 4.7 - Optymalizacja lasu losowego

## Specyfikacja modelu
```{r}
# Specyfikacja modelu lasu losowego z parametrami do dostrojenia
rf_spec <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 1000
) |>
  set_engine("ranger") |>
  set_mode("classification")

# Utworzenie workflow
rf_workflow <- workflow() |>
  add_model(rf_spec) |>
  add_recipe(air_recipe)
```

## Przygotowanie siatki parametrów
```{r}
# Stworzenie siatki parametrów dla lasu losowego
rf_grid <- grid_regular(
  mtry(range = c(2, 8)),
  min_n(range = c(5, 20)),
  levels = 6
)

print("Siatka parametrów dla lasu losowego:")
rf_grid
```

## Dostrajanie modelu lasu losowego
```{r}
# Dostrajanie modelu
rf_tuning <- tune_grid(
  rf_workflow,
  resamples = folds,
  grid = rf_grid,
  metrics = metrics
)

# Wyświetlenie najlepszych wyników
print("Najlepsze wyniki dla lasu losowego:")
show_best(rf_tuning, "accuracy")
```

## Finalizacja modelu lasu losowego
```{r}
# Wybór najlepszych parametrów
best_rf <- select_best(rf_tuning, "accuracy")

# Finalizacja workflow
final_rf_workflow <- finalize_workflow(
  rf_workflow,
  best_rf
)

# Dopasowanie finalnego modelu
final_rf_fit <- last_fit(
  final_rf_workflow,
  split
)

# Wyniki końcowe
print("Wyniki końcowe lasu losowego:")
collect_metrics(final_rf_fit)

# Ważność zmiennych
final_rf_fit |>
  extract_workflow() |>
  extract_fit_parsnip() |>
  vip()
```

# Porównanie modeli
```{r}
# Zbieranie predykcji z obu modeli
tree_predictions <- collect_predictions(final_tree_fit)
rf_predictions <- collect_predictions(final_rf_fit)

# ROC krzywe
tree_roc <- tree_predictions |>
  roc_curve(ozone, .pred_Niskie) |>
  mutate(model = "Decision Tree")

rf_roc <- rf_predictions |>
  roc_curve(ozone, .pred_Niskie) |>
  mutate(model = "Random Forest")

# Połączenie wyników
bind_rows(tree_roc, rf_roc) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
  geom_line() +
  geom_abline(lty = 2, alpha = 0.5) +
  coord_equal() +
  labs(title = "Porównanie krzywych ROC dla obu modeli")
```